Rebecca Goodwin
rj2339

Someone, somewhere is recording everything we do on a daily basis. Data such as what we buy, our phone's location, what terms we search through Google, are all collected (often, but not always, anonymously.) For better or worse, big data is changing the way we perceive the world around us. Big data not only tells us about the world as it currently is, but has the potential to shape human interactions in the future. This is a powerful ability and we must be careful to use it wisely.

The big data is, in general, about using huge sets of data to draw conclusions. The term is a very broad one, encompassing everything from drawing scientific conclusions from datasets, to analyzing vast amounts of search terms to try to target ads for a particular user. Some of the data analysis techniques discussed in this paper are examples of data mining. Big data and data mining are not exactly interchangeable, though they have similar meanings. Data mining refers to specific pattern-finding algorithms used on large datasets, while big data more generally refers to the general analysis of large datasets. Three general categories of data mining are anomaly detection, association learning, and cluster detection. (Furnas) Speaking more generally about big data, the buzzword does not just refer to making use of ever-increasingly large data sets.  "The key feature of the paradigmatic change is that analytic treatment of data is systematically placed at the forefront of intelligent decision-making (Hilbert, 4)." We are not simply collecting data and coming to simple conclusions, but approaching the world from the viewpoint that with enough data, and enough analysis, we can gain an accurate picture of the way things are. With this information, informed decisions can be made and actions taken.

The use of data to make decisions is not a new idea. Databases have been around for decades.# There are a few things# that have come in to play in recent years. One is that technological advances have allowed more data to be stored and processed more quickly#citation#. Another is that algorithms for finding patterns have grown in sophistication and prevalence (Bollier, 1). These algorithms have enabled processing# of unstructured data. In the past, data needed to be entered in a database to draw useful conclusions from it. However, algorithms now make it possible to find patterns in unstructured data such as texts, social network posts, and blog entries. (Simon, 32-34) #better examples? Unstructured data makes up the vast majority of what is called "Big Data." (Simon, 35).

A huge application of big data is in business. Companies use big data to ensure that their product choices and prices match customers' desires. "Retailers, like Walmart and Kohl’s, analyze sales, pricing and economic, demographic and weather data to tailor product selections at particular stores and determine the timing of price markdowns." (Lohr) This kind of data analysis has obvious advantages from a business perspective. Maximizing profits requires finding the delicate balance between supply and demand, and big data is a key to give insight on finding this sweet spot. As another example of big data's use in business, "shipping companies, like U.P.S., mine data on truck delivery times and traffic patterns to fine-tune routing." (Lohr) The implications of these types of applications is wonderful# multiple perspectives. Less wasted product means better revenue for retailers, less wasted fuel means less pollution. 

And customers' needs are met better than ever. Big data isn't just about optimizing profits for business. The goal of big data analytics is to get an accurate picture of how things are. In some cases, these insights help customers, as well. 

Valocchi, from IBM, pointed out in an interview that "there could be billing disputes that come from customers. Using technology, you can show the lineage of data, to point to errors or proof [about whether the customer's bill correctly reflects] exact consumption." (Danigelis) This type of data could either help or hurt customers depending on particular situations, but it is hard to argue against fairness for all parties, which big data can help achieve. Hunn gives an example of how big data can help customers detect inefficient appliances: "We've developed a range of clip-on sensors [...] that customers can self-install. We're starting to put in new sets of algorithms to look at how efficient your appliances are. [...] We can give maintenance information back to consumers." (Danigelis) This example again shows us that data can be used to benefit the customer, since inefficiencies can be detected and repaired to save money. #Another example from that book

However, not everyone agrees that monitoring and analyzing is always a good thing. One of the biggest concerns about big data is privacy, especially since in many cases, people are not aware that data is even being collected and stored. Earlier, we looked at the advantages big data collection can have for customers. However, a somewhat more sinister side of this is that companies may not necessarily want customers to know exactly how much they know. Charles Duhigg of the New York Times did a story on how the retailer Target carefully chooses its ads for customers. Combinations of items can suggest, for instance, that a customer is pregnant. And these combinations are not necessarily obvious--Andrew Pole, Target's marketing statistician, found that purchases such as unscented lotion and cotton balls could signal a woman was approaching her due date. Target found that customers were put off when they received ads only for maternal items, so it began to mix these ads in with other ads so that targeting (pun intended) would be less apparent. (Duhigg) While there is nothing overtly immoral in this method of sending out ads, it is a bit unsettling that this kind of information is collected and tracked without the customer's knowledge. It probably does not occur to the average customer that their purchases are being tracked by credit card number and that seemingly unrelated purchases are analyzed. 

""People start getting very uneasy when buying suggestions are made based on how much we know about this particular person, a practice that takes us into the realm of behavioral targeting.""(Quote from Marc Rotenberg, from Bollier 23).

"An independant suvery of adult Internet [...] users found that two-thirds of users object to online tracking by advertisers. Respondents particularly disliked behavioral advertising, in which commercial websites tailor ads based on an individual's Web behavior." (Bollier, 24).
""Vendors are using Big Data to try to acquire the consumer," [...] and they are doing that by using technologies that are beyond the reach of the consumer by orders of magnitude." (Bolier, 24).

Harrah's Entertainmnet CEO Gary Loveman whote in the Harvard Buisiness Review about how sophisticated data mining techniques were used to target customers very effectively. #connect "Many gambling addicts were trying to quit, only to be lured back to teh tables by remarkably enticing offers in the mail." (Simon, 69).

Google was fined by the Federal Trade Commission in August 2012 "to settle charges that it had bypassed privacy settings in Apple's Safari browser to be able to track users of the browser and show them advertisements." (Simon, 186).

"Much of the data, however, is also about the users’ colleagues, friends, and others they come into contact with. Social media providers are gathering and exploiting vast amounts of personal data, without quality controls and without the consent of the individuals to whom that data relates. Individuals who volunteer such data have moral responsibility for their actions, but little or no legal responsibility. In some social media systems, such as Facebook, biometric and other connection linkages can be set up without the knowledge or permission of the individuals affected, typically by tagging people in photo- graphs. Service providers, meanwhile, can use obscurity, data havens, jurisdictional arbitrage, and market power to escape data protection laws. " (Wigan/Clark, 49).

"Privacy is hardly the only problem associated with Big Data. Some people become disheveled when tehy find out that Google tracks their searches adn YouTube videos viewed. In OCtorber 201-, then-CEO Eric Schmidt spoke to the The Atlantic about a wide range of isses, including privacy. He offered up a bunch of juicy sound bites, including, "We kno whwhere you are. We know where you've been. We can more or less know whawt you're thining about."" (Simon, 188)

"A recent M.I.T. STudy found that geo-location data patterns can successfully predict people's future locations and social interactions." (Bollier, 17).
#from Eagle and Pentland#
"The applications we have presented include ethographic studies of device usage, relationship inference, individual behavior modeling, and group behavior analysis." (Eagle/Pentland, 267).

"The problem is not whether your predictions are more accurate, it's whether they beat the consensus," said Varian. To make money, you've got to predict two things--what's going to happen and what people think is going to happen. You only make money by beating that spread." (Bollier, 20) #prob won't use

Even more concerning than data is collected non-anonymously# is data collecting that is supposedly anonymous--but which can be connected to individuals by clever techniques. The term de-anonymization# refers to taking an anonymized dataset and intersecting it with another, non-anonymous data set connect records with individuals.# This is especially concerning in cases in which individuals may not even be aware data is being collected. For instance, it probably does not occur to the average hospital patient that their anonymized records could be made available to researchers. And it is even less obvious that someone could potentially connect names to records with the right tools.

(Travis--not actually about deanonymization, actually about big brother type stuff in UK)
http://www.theguardian.com/uk/2009/feb/25/database-state-ippr-paper (already have saved as source)
http://www.washingtonpost.com/investigations/us-intelligence-mining-data-from-nine-us-internet-companies-in-broad-secret-program/2013/06/06/3a0c0da8-cebf-11e2-8845-d970ccb04497_story.html (about security)



"Chicago Crime and Crimespotting in Oakland present robust interactive mapping environments that allow users to track instances of crime and police beats in their neighborhood, while examining larger trends with time-elapsed visualizations. Crimespotting pulls daily crime reports from the city’s Crimewatch service and tracks larger trends and provide user-customized services such as neighborhood-specific alerts. The system has been exported and successfully implemented in other cities." (wigan/clark, 48)
#BLue crush


++
"To marketers, this social media data is a treasure trove, both on its own and even more so when linked to other sources. To individuals, it’s a morass of hidden knowledge whose exposure will have some seriously negative conse- quences. Some harmful inferences will arise from what
careful analysis could reveal as false matches. In other cases, ambiguities will provide fertile ground for specula- tion, innuendo, and the exercise of preexisting biases for, and particularly against, racial, ethnic, religious, and so- cioeconomic stereotypes."

(wigan/clark, 49)



"By now, multiplayer online games are also used to track and influence behavior at the same time. Health insurance companies are currently developing multi-layer online games that aim at increasing the fitness levels of their clients. Such games are fed with data from insurance claims and medical records, and combine data from the virtual world and the real world. Points can be earned by checking into the gym or ordering a healthy lunch. The goal is to reduce health care cost, and to increase labor productivity and quality of life " (Hilbert, 12)

However, not everyone agrees that monitoring and analyzing is always a good thing. A common concern is that when data is collected about our every move and analyzed by the government, we have taken our first step towards a Big Brother society. One example of a disconcerting program is the Total Information Awareness program (TIA.) TIA was proposed to monitor American citizens' activities, including emails, phone calls, and medical records. While the program was officially discontinued, the core of the program remains. #citation# 
#PRISM 
poulos
"Under the program, which is being implemented with little public attention, sercurity inverstigations can be launched when governmnet employees showing "incators of insider threat behavior" are reported by co-workers, according to previously undisclosed administration documents obtained by McClatchy. nvestigations also can be triggered when "suspicious user behavior" is detected by computer network monitoring and reported to "insider threat personnel."


"[...] a former military operative regularly briefed by members of the intelligence community--says this particular program has roots going back at least to the 1980s and was set up with help from the Defense Intelligence Agency. He has been told that the program utilizes software that makes predictive judments of targets' behavior and tracks their circle of assiciations with "social network analysis' and artificial intelligence modeling tools. "The more data you have on a particular target, the better [the software] can predict what the target will do, where the target will go, who it will turn to for help," he says. "Main Core is the table of contents for all the illegal information that the U.S government has [compiled] on specific targets." (Ketcham, 83)

"What’s new today is the amount of data that can be kept and searched, the sense of being constantly observed, the precision of the surveillance, and the merg- ing of data from multiple sources. Searches, emails, geographic posi- tion, and other observations com- bine to deliver ads for specific products in your particular location. So, when the government decided to look for terrorists, it went to the corporations that had the data." 
...
we now know that the US government has been piggybacking its surveillance on commercial ser- vices. It’s been collecting metadata about everybody’s telephone calls for more than a decade, while tele- phone companies have been using the same information commer- cially. Mobile telephone carriers exploit location data from your calls and sell it to others; see, for exam- ple, Verizon’s “Precision Market Insights” service.3 Alerting based on the contents of non-US email seems similar to ad targeting based on Gmail and Twitter content."
(Lesk, 86)

"Erroneous data propagates itself into incorrect deductions. Sandy Pentland of the Massachusetts Insti- tute of Technology suggests that 70 to 80 percent of machine learning results are wrong.8 This doesn’t even have to involve mistakes in data; it can simply be a result of searching too hard to find something." [correlation between number of phone calls made in Washingotn, DC, and the level of the POtomac River. Caused by raining, correclation is real but not the causation] [airline companies chargin some higher fares.] "“Big data” in government hands is already used for activities like the “no fly” list and border searches." "For example, research- ers at Kaiser Permanente found that children born to mothers who used antidepressant drugs during pregnancy have double the risk of autism-related illness. If this leads to a way to prevent autism, that’s good. If it means that medical insurers will start refusing cover- age to families in which someone uses antidepressants, depriving them of medical care, that’s some- thing most people would consider bad. There are real risks to pub- lic health if people avoid seeing doctors for fear that knowledge of medical problems will be used against them." (Lesk, 87).

p. 88: Other way around: Talks about consumers monitoring businesses. Also mentions fear of making one mistake on social media stifling entrepreneurship


Federal employees and contractors are asked to pay particular attention to the lifestyles, attitudes and behaviors-like financial troubles, odd working hours or unexplained travel-of co-workers as a way to predict whether they might to "hard to the United States." Managers of special insider threat officies will have "regular, timely, and, if possible, electronic, access to employees' personnel, payroll, disciplinary and "personal contact" files, as well as records of their use of classified and unclassified computer netwroks, polygraph results, travel reports and financial disclosure forms." (Poulos, 1)

"In four new orders, which remain classified, the court defined massive data sets as “facilities” and agreed to certify periodically that the government had reasonable procedures in place to minimize collection of “U.S. persons” data without a warrant." (Gellman/Poitras, 2)
http://www.washingtonpost.com/investigations/us-intelligence-mining-data-from-nine-us-internet-companies-in-broad-secret-program/2013/06/06/3a0c0da8-cebf-11e2-8845-d970ccb04497_story_3.html (no easy way to print)



The biggest concern is # mistakenly identifying a law-abiding citizen as a potential threat. An open letter to the government by the Association for Computing Machinery club asks the question, "Is any level of false positive acceptable - and Constitutional - in such a system?" If we are simply analyzing data to, say, classify spam, this question is not nearly so important. We will want to minimize false positives, of course, but the mistake is not nearly so grave as if a human is falsely accused of a crime of which he is innocent. When we are talking about actual humans, a mistake becomes a much bigger deal. A founding premise of our country is that anyone is innocent until proven guilty. 

While probabilistic data is evidence, the people examining such evidence may be too quick to put too much stock in it. For instance, Stephen Baker of Business Week came across a story about an FBI agent who found a correlation between hummus consumption and a neighborhood's potential to be a refuge for terrorists (Bollier). He says#,"The prjudices of a society are reflected in teh algorithms that are searched." While hummus correlation is not an overt accusation, it still challenges a basic principle that citizens should be allowed a clean, unbiased slate. Suppose that a murder is committed and cell phone data reveals I was within walking distance of the crime a few minutes before it happened. This piece of data is evidence that no doubt should weigh into the decision of my guilt. It is not enough by itself to convict me, but combined with other evidence could lead to a strong case for my guilt. But suppose instead the piece of data is that I belong to a race that has been statistically shown more likely to commit this type of crime. Should this sort of evidence weigh into the judge's decision? Many reasonable people would say no, it is important for the judge to be unbiased. But in the growing paradigm of big data, this could be viewed as evidence just like any other piece of data. If I am indeed innocent, other evidence should weigh in my favor. But the question is whether my race should have weighed into the decision at at all. #Should probably tone the speculation down#
#need more quotes!



An alternative opinion is that probabilistic data is a legitimate basis for probable cause. Kim Taiple, founder of executive director of the Center for Advanced Studies in Science and Technology, has the opinion that "'If you start from the premise that data is going to exist and the data may be relevant for making a judgment that is important to society', then the goal should not be to ban the use of correlations and data analysis." (Lohr) He compares data to guns--we should control their abuse, but not take them (or data analysis) away. #connect# What makes probabilistic data so disconcerting is that it is not immediately obvious when complicated algorithms obfuscate# why someone# is suspicious. Rotenberg# has proposed that when using probabilistic evidence, transparency is necessary--#perhaps to the point of disclosing algorithms used to make the accusation. He said, "if you're going to make decisions about people--such as preventing them from boarding a plan or detaining them as a security risk--then there has to be some fact that someone will stand behind that provides the basis of the decision." (Bollier, 34).
#flesh out

"That is because the premises of suspicion are not necessarilly discernible when databases, using undisclosed algorithms, identify patterns of inference and assert probabilistic ccause. "If you're going to make decisions about people--such as preventing them from boarding a plan or detaining them as a security risk--then there has to be some fact that someone will stand behind that provides the basis of the decision," said Rotenberg. Law enforcement authorities naturally would like to shift to the easier standard of probabilistic cause, he said. But this should require greater transparency, such as disclosing the computing alorithms and inferential reasoning that suggest a security risk" (Bollier, 34).

Chicago Crime and Crimespotting in Oakland present robust interactive mapping environments that allow users to track instances of crime and police beats in their neighborhood, while examining larger trends with time-elapsed visualizations. Crimespotting pulls daily crime reports from the city’s Crimewatch service and tracks larger trends and provide user- customized services such as neighborhood-specific alerts. The system has been exported and successfully implemented in other cities.(hilbert, 9)

"Now, better predictions and more accurate forecasts should be confused with perfect predictions and forecasts. Those who expect Big Data to predict the future with certainty will ultimately be disappointed. Big Data isn't chemistry or algebra. Certitude evades us; Big Data only serves to reduce it." (Simon, 57)

In the Foundation Trilogy, Isaac Asimov explores the idea that the future can be predicted by a combination of history, psychology, and statistics. In the prequel, "Prelude to the Foundation," he brings up an interesting point--that the "predicting" the future itself has an effect on what will happen. The plot focuses on a world leader who is trying to get a "prediction" of his continued beneficial reign. Have we seen this kind of "predicting" in our own world?
As Kim Taipale, the Founder and Executive Director of the Center for Advanced Studies in Science and Technology said at the Eighteenth Annual Aspen Institue Roundtable on Information Technology, "[It is] the classic Heisenberg principle problem. Once data is made available and visualized, people can actually act in ways to change the data as a result of having seen it. He was specifically referring to "Google Bombing," the practice of gaming the Google search engine to "raise the ranking of a given page in the search results." (Bollier) But there are much deeper implications than just trying to game the system. Making decisions based on big data can influence society itself.
"Intellectually, online search ser- vices are now getting quite good at showing you only opinions with which you will agree. Eli Pariser calls this the “filter bubble,” a world in which, at the extreme, we’d never see anything new, just things we already believe.9 Does that increase divisiveness and partisanship in society, or is it just saving you read- ing time?" (lesk, 87) 

#Netflix Qwikster fiasco, stock drop magnified by people complaining on Facebook and Twitter. Shows Big Data can be both good and bad for company (Simon, 59).
#Subprime mortgage thing, not sure if relevant (Simon, 60).
"Models can create what data scientists call a behavioral loop. A person feeds in data, which is collected by an algorithm that then presents the user with choices, thus steering behavior.
Consider Facebook. You put personal data on your Facebook page, and Facebook’s software tracks your clicks and your searches on the site. Then, algorithms sift through that data to present you with “friend” suggestions." (lohr, Sure, Big Data Is Great. But So Is Intuition.)

# maybe delete this, definitely scale back
Big data has been used to identify trends and correlation in society. However, I make the case by merely identifying current trends can have an influence on the direction (or lack thereof) these trends can take. Let us examine the common stereotype that men are naturally more suited to math than women. Studies have shown that women consistently score lower on math tests than men. However, it is interesting that other studies have shown that when young girls are told females do worse on particular tasks, they in fact do worse. However, if they are ignorant of this "disadvantage," they perform the same (Cimpian.) This is not necessarily to say whether men or women are intrinsically better at math, but it is a clue into how societal expectations can influence actual trends. A different study by Robert Rosenthal has shown that when teachers are told they have some students who have scored highly on a test that predicts growth in IQ, those students in fact do better--despite the fact the fact that the "high-scoring" children were actually chosen at random (Rosenthal). Both of these studies tell us something: prior beliefs absolutely have an effect on the future. Suppose data shows people of minority races are more likely to commit crime. Let us suppose this data is without question. The issue is that this very knowledge can impact future events. Minorities may be treated with suspicion, and may on a subconscious level think, "If I'm already being treated like a criminal, why not act like one?" This of course will generate more data confirming the race/crime correlation which will reinforce people's beliefs in a positive feedback loop. The tragedy is that had this data not been known, perhaps the outcome could have been different. In an age inundated with even more data that has the potential to shape our beliefs, it is imperative that we recognize the human ability to shape future society based on beliefs about the present.
# end maybe delete

While I have argued that there is the potential for unintended consequences as a result of data mining, there is also the potential of very intentionally shaping society on a global scale. Global Pulse is a fascinating project that looks to do this#. Its goal is to reduce major issues  on a global scale. Global Pulse "[...] will conduct so-called sentiment analysis of messages in social networks and text messages — using natural-language deciphering software — to help predict job losses, spending reductions or disease outbreaks in a given region. The goal is to use digital early-warning signals to guide assistance programs in advance to, for example, prevent a region from slipping back into poverty" (Lohr) Big data could change our very future--previously unpredictable crises could now potentially be diverted. As another example of big data used to predict societal problems, "in economic forecasting, research has shown that trends in increasing or decreasing volumes of housing-related search queries in Google are a more accurate predictor of house sales in the next quarter than the forecasts of real estate economists." (Lohr)

Like it or not, we are in the information age. While this paper brings up several concerns about big data's implications, I am not at all arguing that big data processing should cease. Indeed, given the sheer amount of data generated constantly, it would be fruitless to argue that we should stop collecting or fail to utilize it. However, it is important to realize that data does not always paint an accurate picture, and recognize that data analysis can have negative repercussions. Big data has the potential to change the way society functions, and it is our responsibility to ensure this influence will be a positive one.


In another application, an analysis of the 140 character long microblogging service Twitter showed that it
7
Hilbert, Big Data for Dev.; pre-published version, Jan. 2013; Contact: martinhilbert@gmail.com
contained important information about the spread of the 2010 Haitian cholera outbreak and was up available up to two weeks earlier than official statistics (Chunara, Andrews and Brownstein, 2012). (hilbert)





